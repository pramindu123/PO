{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbbc9048",
   "metadata": {},
   "source": [
    "# Purchase Order Image Reader\n",
    "\n",
    "This notebook reads purchase order images, extracts data using OpenCV and OCR, and outputs the results to a CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe9bca8",
   "metadata": {},
   "source": [
    "## 1. Install and Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "424c25f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# !pip install opencv-python pytesseract pandas numpy pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c697252a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "# Set the Tesseract executable path (located in tessaret folder)\n",
    "pytesseract.pytesseract.tesseract_cmd = r'D:\\Year 4 Sem 1\\PO\\PO\\tessaret\\tesseract.exe'\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583e9152",
   "metadata": {},
   "source": [
    "## 2. Image Preprocessing Functions\n",
    "\n",
    "These functions help improve OCR accuracy by preprocessing the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f1501620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing functions defined!\n"
     ]
    }
   ],
   "source": [
    "def load_image(image_path):\n",
    "    \"\"\"\n",
    "    Load an image using PIL first (supports more formats like webp), then convert to OpenCV format.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to the image file\n",
    "    \n",
    "    Returns:\n",
    "        Image in OpenCV BGR format\n",
    "    \"\"\"\n",
    "    # Use PIL to load the image (supports webp, png, jpg, etc.)\n",
    "    pil_image = Image.open(image_path)\n",
    "    \n",
    "    # Convert to RGB if necessary\n",
    "    if pil_image.mode != 'RGB':\n",
    "        pil_image = pil_image.convert('RGB')\n",
    "    \n",
    "    # Convert PIL image to numpy array (OpenCV format)\n",
    "    img = np.array(pil_image)\n",
    "    \n",
    "    # Convert RGB to BGR (OpenCV uses BGR)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"\n",
    "    Preprocess an image for better OCR results.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to the image file\n",
    "    \n",
    "    Returns:\n",
    "        Preprocessed image ready for OCR\n",
    "    \"\"\"\n",
    "    # Read the image using PIL-based loader\n",
    "    img = load_image(image_path)\n",
    "    \n",
    "    if img is None:\n",
    "        raise ValueError(f\"Could not read image: {image_path}\")\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply noise reduction\n",
    "    denoised = cv2.fastNlMeansDenoising(gray, None, 10, 7, 21)\n",
    "    \n",
    "    # Apply adaptive thresholding for better text detection\n",
    "    thresh = cv2.adaptiveThreshold(\n",
    "        denoised, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2\n",
    "    )\n",
    "    \n",
    "    # Deskew the image if needed\n",
    "    thresh = deskew_image(thresh)\n",
    "    \n",
    "    return thresh\n",
    "\n",
    "\n",
    "def deskew_image(image):\n",
    "    \"\"\"\n",
    "    Deskew an image to straighten text lines.\n",
    "    \"\"\"\n",
    "    coords = np.column_stack(np.where(image > 0))\n",
    "    if len(coords) == 0:\n",
    "        return image\n",
    "    \n",
    "    angle = cv2.minAreaRect(coords)[-1]\n",
    "    \n",
    "    if angle < -45:\n",
    "        angle = -(90 + angle)\n",
    "    else:\n",
    "        angle = -angle\n",
    "    \n",
    "    # Only deskew if the angle is significant\n",
    "    if abs(angle) > 0.5:\n",
    "        (h, w) = image.shape[:2]\n",
    "        center = (w // 2, h // 2)\n",
    "        M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "        image = cv2.warpAffine(\n",
    "            image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE\n",
    "        )\n",
    "    \n",
    "    return image\n",
    "\n",
    "\n",
    "def enhance_image(image_path):\n",
    "    \"\"\"\n",
    "    Apply multiple enhancement techniques to improve OCR accuracy.\n",
    "    \"\"\"\n",
    "    # Use PIL-based loader to support webp and other formats\n",
    "    img = load_image(image_path)\n",
    "    \n",
    "    if img is None:\n",
    "        raise ValueError(f\"Could not read image: {image_path}\")\n",
    "    \n",
    "    # Resize image if too small (OCR works better on larger images)\n",
    "    height, width = img.shape[:2]\n",
    "    if width < 1000:\n",
    "        scale = 1000 / width\n",
    "        img = cv2.resize(img, None, fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    enhanced = clahe.apply(gray)\n",
    "    \n",
    "    # Apply bilateral filter to reduce noise while keeping edges sharp\n",
    "    filtered = cv2.bilateralFilter(enhanced, 9, 75, 75)\n",
    "    \n",
    "    # Apply Otsu's thresholding\n",
    "    _, binary = cv2.threshold(filtered, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    return binary\n",
    "\n",
    "\n",
    "print(\"Preprocessing functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8836405d",
   "metadata": {},
   "source": [
    "## 3. OCR and Text Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b21746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR functions defined!\n"
     ]
    }
   ],
   "source": [
    "def extract_text_from_image(image_path, preprocess=True, processed_img=None):\n",
    "    \"\"\"\n",
    "    Extract text from an image using OCR.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to the image file\n",
    "        preprocess: Whether to apply preprocessing\n",
    "        processed_img: Optional preprocessed image to use directly\n",
    "    \n",
    "    Returns:\n",
    "        Extracted text as a string\n",
    "    \"\"\"\n",
    "    if processed_img is not None:\n",
    "        img_for_ocr = processed_img\n",
    "    elif preprocess:\n",
    "        img_for_ocr = enhance_image(image_path)\n",
    "    else:\n",
    "        img_for_ocr = cv2.imread(image_path)\n",
    "    \n",
    "    # Configure Tesseract for better results\n",
    "    custom_config = r'--oem 3 --psm 6'\n",
    "    \n",
    "    # Extract text\n",
    "    text = pytesseract.image_to_string(img_for_ocr, config=custom_config)\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def extract_text_with_boxes(image_path):\n",
    "    \"\"\"\n",
    "    Extract text with bounding box information.\n",
    "    \"\"\"\n",
    "    processed_img = enhance_image(image_path)\n",
    "    \n",
    "    # Get detailed OCR data\n",
    "    data = pytesseract.image_to_data(processed_img, output_type=pytesseract.Output.DICT)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "print(\"OCR functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4a0a29",
   "metadata": {},
   "source": [
    "## 4. Purchase Order Data Parsing Functions\n",
    "\n",
    "These functions parse the extracted text to identify common purchase order fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "48fb24a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing functions defined!\n"
     ]
    }
   ],
   "source": [
    "def parse_purchase_order(text):\n",
    "    \"\"\"\n",
    "    Parse extracted text to identify purchase order fields.\n",
    "    \n",
    "    Args:\n",
    "        text: Raw text extracted from OCR\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing parsed PO data\n",
    "    \"\"\"\n",
    "    po_data = {\n",
    "        'po_number': None,\n",
    "        'date': None,\n",
    "        'vendor_name': None,\n",
    "        'vendor_address': None,\n",
    "        'total_amount': None,\n",
    "        'items': [],\n",
    "        'raw_text': text\n",
    "    }\n",
    "    \n",
    "    lines = text.split('\\n')\n",
    "    \n",
    "    # Patterns for common PO fields\n",
    "    po_patterns = [\n",
    "        r'P\\.?O\\.?\\s*(?:Number|No\\.?|#)?\\s*[:\\s]*([A-Z0-9-]+)',\n",
    "        r'Purchase\\s*Order\\s*(?:Number|No\\.?|#)?\\s*[:\\s]*([A-Z0-9-]+)',\n",
    "        r'Order\\s*(?:Number|No\\.?|#)?\\s*[:\\s]*([A-Z0-9-]+)',\n",
    "    ]\n",
    "    \n",
    "    date_patterns = [\n",
    "        r'Date\\s*[:\\s]*([0-9]{1,2}[/-][0-9]{1,2}[/-][0-9]{2,4})',\n",
    "        r'([0-9]{1,2}[/-][0-9]{1,2}[/-][0-9]{2,4})',\n",
    "        r'([A-Za-z]+\\s+[0-9]{1,2},?\\s+[0-9]{4})',\n",
    "    ]\n",
    "    \n",
    "    amount_patterns = [\n",
    "        r'Total\\s*[:\\s]*\\$?([0-9,]+\\.?[0-9]*)',\n",
    "        r'Grand\\s*Total\\s*[:\\s]*\\$?([0-9,]+\\.?[0-9]*)',\n",
    "        r'Amount\\s*Due\\s*[:\\s]*\\$?([0-9,]+\\.?[0-9]*)',\n",
    "        r'\\$\\s*([0-9,]+\\.[0-9]{2})',\n",
    "    ]\n",
    "    \n",
    "    # Extract PO Number\n",
    "    for pattern in po_patterns:\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            po_data['po_number'] = match.group(1).strip()\n",
    "            break\n",
    "    \n",
    "    # Extract Date\n",
    "    for pattern in date_patterns:\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            po_data['date'] = match.group(1).strip()\n",
    "            break\n",
    "    \n",
    "    # Extract Total Amount\n",
    "    amounts = []\n",
    "    for pattern in amount_patterns:\n",
    "        matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "        for m in matches:\n",
    "            try:\n",
    "                amount = float(m.replace(',', ''))\n",
    "                amounts.append(amount)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    if amounts:\n",
    "        po_data['total_amount'] = max(amounts)  # Usually the largest amount is the total\n",
    "    \n",
    "    # Extract line items (simplified - looks for quantity, description, price patterns)\n",
    "    item_pattern = r'([0-9]+)\\s+(.+?)\\s+\\$?([0-9,]+\\.?[0-9]*)'\n",
    "    item_matches = re.findall(item_pattern, text)\n",
    "    \n",
    "    for match in item_matches:\n",
    "        try:\n",
    "            qty = int(match[0])\n",
    "            desc = match[1].strip()\n",
    "            price = float(match[2].replace(',', ''))\n",
    "            if qty > 0 and qty < 10000 and price > 0:\n",
    "                po_data['items'].append({\n",
    "                    'quantity': qty,\n",
    "                    'description': desc,\n",
    "                    'price': price\n",
    "                })\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return po_data\n",
    "\n",
    "\n",
    "print(\"Parsing functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec7700d",
   "metadata": {},
   "source": [
    "## 5. Main Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4bbea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing functions defined!\n"
     ]
    }
   ],
   "source": [
    "def process_single_image(image_path, preprocess_output_dir=None):\n",
    "    \"\"\"\n",
    "    Process a single purchase order image.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to the PO image\n",
    "        preprocess_output_dir: Optional folder to save preprocessed image\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing extracted PO data\n",
    "    \"\"\"\n",
    "    print(f\"Processing: {image_path}\")\n",
    "    \n",
    "    # Preprocess image once\n",
    "    processed_img = enhance_image(image_path)\n",
    "    \n",
    "    # Save preprocessed image if folder provided\n",
    "    if preprocess_output_dir:\n",
    "        os.makedirs(preprocess_output_dir, exist_ok=True)\n",
    "        base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "        preprocessed_path = os.path.join(preprocess_output_dir, f\"{base_name}_preprocessed.png\")\n",
    "        cv2.imwrite(preprocessed_path, processed_img)\n",
    "    \n",
    "    # Extract text from image\n",
    "    text = extract_text_from_image(image_path, preprocess=False, processed_img=processed_img)\n",
    "    \n",
    "    # Parse the extracted text\n",
    "    po_data = parse_purchase_order(text)\n",
    "    \n",
    "    # Add filename to the data\n",
    "    po_data['source_file'] = os.path.basename(image_path)\n",
    "    \n",
    "    return po_data\n",
    "\n",
    "\n",
    "def process_multiple_images(image_folder, extensions=['*.png', '*.jpg', '*.jpeg', '*.tiff', '*.bmp', '*.webp', '*.gif'], preprocess_output_dir=None):\n",
    "    \"\"\"\n",
    "    Process multiple purchase order images from a folder.\n",
    "    \n",
    "    Args:\n",
    "        image_folder: Path to the folder containing PO images\n",
    "        extensions: List of image file extensions to process\n",
    "        preprocess_output_dir: Optional folder to save preprocessed images\n",
    "    \n",
    "    Returns:\n",
    "        List of dictionaries containing extracted PO data\n",
    "    \"\"\"\n",
    "    all_po_data = []\n",
    "    \n",
    "    # Find all image files\n",
    "    image_files = []\n",
    "    for ext in extensions:\n",
    "        image_files.extend(glob.glob(os.path.join(image_folder, ext)))\n",
    "        image_files.extend(glob.glob(os.path.join(image_folder, ext.upper())))\n",
    "    \n",
    "    # Remove duplicates and sort\n",
    "    image_files = sorted(list(set(image_files)))\n",
    "    \n",
    "    print(f\"Found {len(image_files)} images to process:\")\n",
    "    for f in image_files:\n",
    "        print(f\"  - {f}\")\n",
    "    \n",
    "    for image_path in image_files:\n",
    "        try:\n",
    "            po_data = process_single_image(image_path, preprocess_output_dir=preprocess_output_dir)\n",
    "            all_po_data.append(po_data)\n",
    "            print(f\"  ✓ Successfully processed: {os.path.basename(image_path)}\")\n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            print(f\"  ✗ Error processing {image_path}:\")\n",
    "            print(f\"    {str(e)}\")\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    return all_po_data\n",
    "\n",
    "\n",
    "print(\"Processing functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a14884",
   "metadata": {},
   "source": [
    "## 6. CSV Export Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ece36565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export functions defined!\n"
     ]
    }
   ],
   "source": [
    "def export_to_csv(po_data_list, output_path='purchase_orders.csv'):\n",
    "    \"\"\"\n",
    "    Export parsed purchase order data to CSV.\n",
    "    \n",
    "    Args:\n",
    "        po_data_list: List of dictionaries containing PO data\n",
    "        output_path: Path for the output CSV file\n",
    "    \n",
    "    Returns:\n",
    "        Path to the created CSV file\n",
    "    \"\"\"\n",
    "    # Prepare data for CSV\n",
    "    csv_data = []\n",
    "    \n",
    "    for po in po_data_list:\n",
    "        # Create a row for the main PO data\n",
    "        row = {\n",
    "            'Source File': po.get('source_file', ''),\n",
    "            'PO Number': po.get('po_number', ''),\n",
    "            'Date': po.get('date', ''),\n",
    "            'Vendor Name': po.get('vendor_name', ''),\n",
    "            'Total Amount': po.get('total_amount', ''),\n",
    "            'Number of Items': len(po.get('items', [])),\n",
    "        }\n",
    "        csv_data.append(row)\n",
    "    \n",
    "    # Create DataFrame and export to CSV\n",
    "    df = pd.DataFrame(csv_data)\n",
    "    df.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"Exported {len(csv_data)} purchase orders to: {output_path}\")\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "\n",
    "def export_detailed_csv(po_data_list, output_path='purchase_orders_detailed.csv'):\n",
    "    \"\"\"\n",
    "    Export detailed purchase order data including line items to CSV.\n",
    "    \n",
    "    Args:\n",
    "        po_data_list: List of dictionaries containing PO data\n",
    "        output_path: Path for the output CSV file\n",
    "    \n",
    "    Returns:\n",
    "        Path to the created CSV file\n",
    "    \"\"\"\n",
    "    csv_data = []\n",
    "    \n",
    "    for po in po_data_list:\n",
    "        items = po.get('items', [])\n",
    "        \n",
    "        if items:\n",
    "            for item in items:\n",
    "                row = {\n",
    "                    'Source File': po.get('source_file', ''),\n",
    "                    'PO Number': po.get('po_number', ''),\n",
    "                    'Date': po.get('date', ''),\n",
    "                    'Total Amount': po.get('total_amount', ''),\n",
    "                    'Item Quantity': item.get('quantity', ''),\n",
    "                    'Item Description': item.get('description', ''),\n",
    "                    'Item Price': item.get('price', ''),\n",
    "                }\n",
    "                csv_data.append(row)\n",
    "        else:\n",
    "            # Add a row even if no items were detected\n",
    "            row = {\n",
    "                'Source File': po.get('source_file', ''),\n",
    "                'PO Number': po.get('po_number', ''),\n",
    "                'Date': po.get('date', ''),\n",
    "                'Total Amount': po.get('total_amount', ''),\n",
    "                'Item Quantity': '',\n",
    "                'Item Description': '',\n",
    "                'Item Price': '',\n",
    "            }\n",
    "            csv_data.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(csv_data)\n",
    "    df.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"Exported detailed data to: {output_path}\")\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "\n",
    "print(\"Export functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbceb51",
   "metadata": {},
   "source": [
    "## 7. Visualization and Preview Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f71fc995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization functions defined!\n"
     ]
    }
   ],
   "source": [
    "def visualize_detection(image_path, output_path=None):\n",
    "    \"\"\"\n",
    "    Visualize text detection by drawing bounding boxes on the image.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to the image file\n",
    "        output_path: Optional path to save the annotated image\n",
    "    \n",
    "    Returns:\n",
    "        Annotated image\n",
    "    \"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    # Get OCR data with bounding boxes\n",
    "    data = pytesseract.image_to_data(img, output_type=pytesseract.Output.DICT)\n",
    "    \n",
    "    n_boxes = len(data['text'])\n",
    "    \n",
    "    for i in range(n_boxes):\n",
    "        if int(data['conf'][i]) > 60:  # Only draw boxes with confidence > 60%\n",
    "            (x, y, w, h) = (data['left'][i], data['top'][i], data['width'][i], data['height'][i])\n",
    "            img = cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    \n",
    "    if output_path:\n",
    "        cv2.imwrite(output_path, img)\n",
    "        print(f\"Annotated image saved to: {output_path}\")\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "def preview_preprocessing(image_path):\n",
    "    \"\"\"\n",
    "    Preview the preprocessing steps on an image.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Original image\n",
    "    original = cv2.imread(image_path)\n",
    "    original_rgb = cv2.cvtColor(original, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Preprocessed image\n",
    "    processed = enhance_image(image_path)\n",
    "    \n",
    "    # Display side by side\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 8))\n",
    "    \n",
    "    axes[0].imshow(original_rgb)\n",
    "    axes[0].set_title('Original Image')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(processed, cmap='gray')\n",
    "    axes[1].set_title('Preprocessed Image')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"Visualization functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975a9214",
   "metadata": {},
   "source": [
    "## 8. Run the Purchase Order Reader\n",
    "\n",
    "Configure the paths below and run to process your purchase order images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894b8030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration set!\n",
      "Image folder: d:\\Year 4 Sem 1\\PO\\PO\\images\n",
      "Output folder: d:\\Year 4 Sem 1\\PO\\PO\\output\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CONFIGURATION - Update these paths\n",
    "# ============================================\n",
    "\n",
    "# Get the notebook's directory as the base path\n",
    "NOTEBOOK_DIR = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "if not NOTEBOOK_DIR or NOTEBOOK_DIR == \".\":\n",
    "    NOTEBOOK_DIR = os.getcwd()\n",
    "\n",
    "# Option 1: Process a single image\n",
    "SINGLE_IMAGE_PATH = os.path.join(NOTEBOOK_DIR, \"images\", \"test1.png\")\n",
    "\n",
    "# Option 2: Process multiple images from a folder\n",
    "IMAGE_FOLDER = os.path.join(NOTEBOOK_DIR, \"images\")\n",
    "\n",
    "# Output folder and CSV file paths\n",
    "OUTPUT_FOLDER = os.path.join(NOTEBOOK_DIR, \"output\")\n",
    "OUTPUT_CSV = os.path.join(OUTPUT_FOLDER, \"purchase_orders_output.csv\")\n",
    "OUTPUT_DETAILED_CSV = os.path.join(OUTPUT_FOLDER, \"purchase_orders_detailed.csv\")\n",
    "\n",
    "# Preprocessed images output folder (separate from CSV outputs)\n",
    "PREPROCESSED_FOLDER = os.path.join(NOTEBOOK_DIR, \"preprocessed_images\")\n",
    "\n",
    "# Create output folders if they don't exist\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "os.makedirs(PREPROCESSED_FOLDER, exist_ok=True)\n",
    "\n",
    "print(f\"Configuration set!\")\n",
    "print(f\"Image folder: {IMAGE_FOLDER}\")\n",
    "print(f\"Output folder: {OUTPUT_FOLDER}\")\n",
    "print(f\"Preprocessed images folder: {PREPROCESSED_FOLDER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f4d9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# PROCESS SINGLE IMAGE (uncomment to use)\n",
    "# ============================================\n",
    "\n",
    "# if os.path.exists(SINGLE_IMAGE_PATH):\n",
    "#     # Process the image (also saves preprocessed image)\n",
    "#     po_data = process_single_image(SINGLE_IMAGE_PATH, preprocess_output_dir=PREPROCESSED_FOLDER)\n",
    "#     \n",
    "#     # Display extracted data\n",
    "#     print(\"\\n\" + \"=\"*50)\n",
    "#     print(\"EXTRACTED DATA:\")\n",
    "#     print(\"=\"*50)\n",
    "#     print(f\"PO Number: {po_data.get('po_number', 'Not found')}\")\n",
    "#     print(f\"Date: {po_data.get('date', 'Not found')}\")\n",
    "#     print(f\"Total Amount: {po_data.get('total_amount', 'Not found')}\")\n",
    "#     print(f\"Items found: {len(po_data.get('items', []))}\")\n",
    "#     \n",
    "#     # Export to CSV\n",
    "#     export_to_csv([po_data], OUTPUT_CSV)\n",
    "# else:\n",
    "#     print(f\"Image not found: {SINGLE_IMAGE_PATH}\")\n",
    "#     print(\"Please update SINGLE_IMAGE_PATH with a valid image path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926aec70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 images to process:\n",
      "  - d:\\Year 4 Sem 1\\PO\\PO\\images\\test1.png\n",
      "  - d:\\Year 4 Sem 1\\PO\\PO\\images\\test2.webp\n",
      "Processing: d:\\Year 4 Sem 1\\PO\\PO\\images\\test1.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Successfully processed: test1.png\n",
      "Processing: d:\\Year 4 Sem 1\\PO\\PO\\images\\test2.webp\n",
      "  ✓ Successfully processed: test2.webp\n",
      "\n",
      "==================================================\n",
      "PROCESSED 2 PURCHASE ORDERS\n",
      "==================================================\n",
      "\n",
      "1. test1.png\n",
      "   PO Number: PO-002\n",
      "   Date: Jun 22, 2021\n",
      "   Total: $1564.0\n",
      "\n",
      "2. test2.webp\n",
      "   PO Number: Box\n",
      "   Date: 10/01/2021\n",
      "   Total: $1075.0\n",
      "Exported 2 purchase orders to: d:\\Year 4 Sem 1\\PO\\PO\\output\\purchase_orders_output.csv\n",
      "Exported detailed data to: d:\\Year 4 Sem 1\\PO\\PO\\output\\purchase_orders_detailed.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# PROCESS MULTIPLE IMAGES FROM FOLDER\n",
    "# ============================================\n",
    "\n",
    "if os.path.exists(IMAGE_FOLDER):\n",
    "    # Process all images in the folder (also saves preprocessed images)\n",
    "    all_po_data = process_multiple_images(IMAGE_FOLDER, preprocess_output_dir=PREPROCESSED_FOLDER)\n",
    "    \n",
    "    if all_po_data:\n",
    "        # Display summary\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"PROCESSED {len(all_po_data)} PURCHASE ORDERS\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        for i, po in enumerate(all_po_data, 1):\n",
    "            print(f\"\\n{i}. {po.get('source_file', 'Unknown')}\")\n",
    "            print(f\"   PO Number: {po.get('po_number', 'Not found')}\")\n",
    "            print(f\"   Date: {po.get('date', 'Not found')}\")\n",
    "            print(f\"   Total: ${po.get('total_amount', 'Not found')}\")\n",
    "        \n",
    "        # Export to CSV\n",
    "        export_to_csv(all_po_data, OUTPUT_CSV)\n",
    "        export_detailed_csv(all_po_data, OUTPUT_DETAILED_CSV)\n",
    "    else:\n",
    "        print(\"No images found or processed.\")\n",
    "else:\n",
    "    print(f\"Folder not found: {IMAGE_FOLDER}\")\n",
    "    print(\"Please create the folder and add PO images, or update IMAGE_FOLDER path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81c5052",
   "metadata": {},
   "source": [
    "## 9. View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e82b3ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purchase Orders Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source File</th>\n",
       "      <th>PO Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Vendor Name</th>\n",
       "      <th>Total Amount</th>\n",
       "      <th>Number of Items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test1.png</td>\n",
       "      <td>PO-002</td>\n",
       "      <td>Jun 22, 2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1564.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test2.webp</td>\n",
       "      <td>Box</td>\n",
       "      <td>10/01/2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Source File PO Number          Date  Vendor Name  Total Amount  \\\n",
       "0   test1.png    PO-002  Jun 22, 2021          NaN        1564.0   \n",
       "1  test2.webp       Box    10/01/2021          NaN        1075.0   \n",
       "\n",
       "   Number of Items  \n",
       "0                4  \n",
       "1                5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# View the exported CSV file\n",
    "if os.path.exists(OUTPUT_CSV):\n",
    "    df = pd.read_csv(OUTPUT_CSV)\n",
    "    print(\"Purchase Orders Summary:\")\n",
    "    display(df)\n",
    "else:\n",
    "    print(f\"CSV file not found: {OUTPUT_CSV}\")\n",
    "    print(\"Please run the processing cells above first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a3900277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Purchase Order Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source File</th>\n",
       "      <th>PO Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Total Amount</th>\n",
       "      <th>Item Quantity</th>\n",
       "      <th>Item Description</th>\n",
       "      <th>Item Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test1.png</td>\n",
       "      <td>PO-002</td>\n",
       "      <td>Jun 22, 2021</td>\n",
       "      <td>1564.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Green] Materials LLC Invoice Date Jun</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test1.png</td>\n",
       "      <td>PO-002</td>\n",
       "      <td>Jun 22, 2021</td>\n",
       "      <td>1564.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Desktop furniture</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test1.png</td>\n",
       "      <td>PO-002</td>\n",
       "      <td>Jun 22, 2021</td>\n",
       "      <td>1564.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Plumbing and electrical services</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test1.png</td>\n",
       "      <td>PO-002</td>\n",
       "      <td>Jun 22, 2021</td>\n",
       "      <td>1564.0</td>\n",
       "      <td>2</td>\n",
       "      <td>$</td>\n",
       "      <td>152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test2.webp</td>\n",
       "      <td>Box</td>\n",
       "      <td>10/01/2021</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>1028</td>\n",
       "      <td>Riverside, CA</td>\n",
       "      <td>92501.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test2.webp</td>\n",
       "      <td>Box</td>\n",
       "      <td>10/01/2021</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>2268</td>\n",
       "      <td>DATE:</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test2.webp</td>\n",
       "      <td>Box</td>\n",
       "      <td>10/01/2021</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>Fax: Enter fax POw:</td>\n",
       "      <td>8873632.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test2.webp</td>\n",
       "      <td>Box</td>\n",
       "      <td>10/01/2021</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>1234</td>\n",
       "      <td>567</td>\n",
       "      <td>891.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>test2.webp</td>\n",
       "      <td>Box</td>\n",
       "      <td>10/01/2021</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>3678</td>\n",
       "      <td>Safety Glasses - Clear</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Source File PO Number          Date  Total Amount  Item Quantity  \\\n",
       "0   test1.png    PO-002  Jun 22, 2021        1564.0              2   \n",
       "1   test1.png    PO-002  Jun 22, 2021        1564.0              1   \n",
       "2   test1.png    PO-002  Jun 22, 2021        1564.0              2   \n",
       "3   test1.png    PO-002  Jun 22, 2021        1564.0              2   \n",
       "4  test2.webp       Box    10/01/2021        1075.0           1028   \n",
       "5  test2.webp       Box    10/01/2021        1075.0           2268   \n",
       "6  test2.webp       Box    10/01/2021        1075.0           2021   \n",
       "7  test2.webp       Box    10/01/2021        1075.0           1234   \n",
       "8  test2.webp       Box    10/01/2021        1075.0           3678   \n",
       "\n",
       "                        Item Description  Item Price  \n",
       "0  Green] Materials LLC Invoice Date Jun        22.0  \n",
       "1                      Desktop furniture         1.0  \n",
       "2       Plumbing and electrical services         2.0  \n",
       "3                                      $       152.0  \n",
       "4                          Riverside, CA     92501.0  \n",
       "5                                  DATE:        10.0  \n",
       "6                    Fax: Enter fax POw:   8873632.0  \n",
       "7                                    567       891.0  \n",
       "8                 Safety Glasses - Clear         5.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# View detailed CSV with line items\n",
    "if os.path.exists(OUTPUT_DETAILED_CSV):\n",
    "    df_detailed = pd.read_csv(OUTPUT_DETAILED_CSV)\n",
    "    print(\"Detailed Purchase Order Data:\")\n",
    "    display(df_detailed)\n",
    "else:\n",
    "    print(f\"Detailed CSV file not found: {OUTPUT_DETAILED_CSV}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6226a634",
   "metadata": {},
   "source": [
    "## 10. Debug and Test OCR on a Single Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3fd9986b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: View raw OCR output for a single image\n",
    "# Uncomment and update the path to test\n",
    "\n",
    "# TEST_IMAGE = r\"C:\\PO\\test_image.png\"\n",
    "# \n",
    "# if os.path.exists(TEST_IMAGE):\n",
    "#     # Preview preprocessing\n",
    "#     preview_preprocessing(TEST_IMAGE)\n",
    "#     \n",
    "#     # Extract and display raw text\n",
    "#     raw_text = extract_text_from_image(TEST_IMAGE)\n",
    "#     print(\"\\n\" + \"=\"*50)\n",
    "#     print(\"RAW OCR OUTPUT:\")\n",
    "#     print(\"=\"*50)\n",
    "#     print(raw_text)\n",
    "# else:\n",
    "#     print(f\"Test image not found: {TEST_IMAGE}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
